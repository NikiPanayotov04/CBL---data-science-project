{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52059955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Ward code                 Ward name  Dwellings     Risk_Rate  \\\n",
      "0    E05013662   Holborn & Covent Garden       5985  4.385889e-03   \n",
      "1    E05013748     Shepherd's Bush Green       3080  4.309465e-03   \n",
      "2    E09000001            City of London       7330  3.821007e-03   \n",
      "3    E05009377  Hoxton East & Shoreditch       6410  3.821176e-03   \n",
      "4    E05013808                  West End      10270  3.786360e-03   \n",
      "..         ...                       ...        ...           ...   \n",
      "675  E05009368                  Cazenove       5300  0.000000e+00   \n",
      "676  E05013883                   Cathall       4310  0.000000e+00   \n",
      "677  E05013945                  Tolworth       4755  4.669708e-19   \n",
      "678  E05013578             Ruislip Manor       3920  0.000000e+00   \n",
      "679  E05013617            Heston Central       4485  0.000000e+00   \n",
      "\n",
      "     Allocated_Hours  \n",
      "0              200.0  \n",
      "1              197.0  \n",
      "2              174.0  \n",
      "3              174.0  \n",
      "4              173.0  \n",
      "..               ...  \n",
      "675              2.0  \n",
      "676              2.0  \n",
      "677              2.0  \n",
      "678              2.0  \n",
      "679              2.0  \n",
      "\n",
      "[680 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_lsoa = pd.read_parquet(\"../data/processed/census_lsoa.parquet\")\n",
    "\n",
    "lookup = pd.read_csv(\n",
    "    \"../data/lookups/look up LSOA 2021 to ward 2024 merged.csv\",\n",
    "    usecols=[\"LSOA21CD\", \"WD24CD\", \"WD24NM\"]\n",
    ")\n",
    "\n",
    "# Mege on LSOA code\n",
    "df_lsoa = df_lsoa.merge(\n",
    "    lookup,\n",
    "    left_on=\"LSOA code\",\n",
    "    right_on=\"LSOA21CD\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "df_ward_census = (\n",
    "    df_lsoa\n",
    "    .groupby([\"WD24CD\", \"WD24NM\"], as_index=False)\n",
    "    .agg({\"Total: All dwellings\": \"sum\"})\n",
    ")\n",
    "df_ward_census.rename(\n",
    "    columns={\n",
    "        \"WD24CD\": \"Ward code\",\n",
    "        \"WD24NM\": \"Ward name\",\n",
    "        \"Total: All dwellings\": \"Dwellings\"\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "sarima_fc = pd.read_csv(\n",
    "    \"../data/processed/sarima_final_forecast_per_ward.csv\",\n",
    "    parse_dates=[\"Month\"]\n",
    ")\n",
    "first_fc_month = sarima_fc[\"Month\"].min()\n",
    "fc1 = sarima_fc[sarima_fc[\"Month\"] == first_fc_month].copy()\n",
    "\n",
    "df = (\n",
    "    fc1[[\"Ward code\", \"Ward name\", \"mean\"]]\n",
    "    .merge(\n",
    "        df_ward_census[[\"Ward code\", \"Dwellings\"]],\n",
    "        on=\"Ward code\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .rename(columns={\"mean\": \"Forecasted_Burglaries\"})\n",
    ")\n",
    "\n",
    "df[\"Risk_Rate\"] = df[\"Forecasted_Burglaries\"] / df[\"Dwellings\"].replace(0, np.nan)\n",
    "df[\"Risk_Rate\"] = df[\"Risk_Rate\"].clip(lower=0)\n",
    "\n",
    "r_max = df[\"Risk_Rate\"].max()\n",
    "\n",
    "df[\"Allocated_Hours\"] = 200 * (df[\"Risk_Rate\"] / r_max)\n",
    "df[\"Allocated_Hours\"] = df[\"Allocated_Hours\"].clip(lower=2)\n",
    "\n",
    "df[\"Allocated_Hours\"] = df[\"Allocated_Hours\"].round(0) # Integer hours\n",
    "df = df.sort_values(\"Allocated_Hours\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(df[[\n",
    "    \"Ward code\",\n",
    "    \"Ward name\",\n",
    "    \"Dwellings\",\n",
    "    \"Risk_Rate\",\n",
    "    \"Allocated_Hours\"\n",
    "]])\n",
    "\n",
    "df.to_csv(\"../data/processed/ward_hour_allocation.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d8dea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31013.0\n",
      "Set parameter OutputFlag to value 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning for adding constraints: zero or small (< 1e-13) coefficients, ignored\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (win64 - Windows 11.0 (26100.2))\n",
      "\n",
      "CPU model: 12th Gen Intel(R) Core(TM) i7-12700H, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 14 physical cores, 20 logical processors, using up to 20 threads\n",
      "\n",
      "Optimize a model with 681 rows, 681 columns and 2031 nonzeros\n",
      "Model fingerprint: 0xa6422ca0\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-05, 4e+01]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [2e+00, 2e+02]\n",
      "  RHS range        [3e+04, 3e+04]\n",
      "Presolve removed 41 rows and 41 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 640 rows, 640 columns, 1917 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    1.2167987e+02   5.475445e+04   0.000000e+00      0s\n",
      "     639    5.4129239e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 639 iterations and 0.01 seconds (0.02 work units)\n",
      "Optimal objective  5.412923868e+00\n",
      "     Ward code                    Ward name  Predicted_Crime_Count  \\\n",
      "0    E05013810                        Abbey               1.643657   \n",
      "1    E05013808                     West End              36.948608   \n",
      "2    E05013806                   St James's              33.636805   \n",
      "3    E05013793                    Bayswater              31.000000   \n",
      "4    E09000001               City of London              27.919985   \n",
      "..         ...                          ...                    ...   \n",
      "675  E05014107               Myatt's Fields              -0.333300   \n",
      "676  E05011481    Selsdon Vale & Forestdale               0.447649   \n",
      "677  E05011480  Selsdon & Addington Village              -0.666649   \n",
      "678  E05013727             Lewisham Central               0.098110   \n",
      "679  E05013938                Kingston Town              -0.092864   \n",
      "\n",
      "     Alpha (Coverage Factor)  Allocated_Officers_Continuous  \\\n",
      "0                   5.412924                     200.000000   \n",
      "1                   5.412924                     200.000000   \n",
      "2                   5.412924                     182.073467   \n",
      "3                   5.412924                     167.800640   \n",
      "4                   5.412924                     151.128752   \n",
      "..                       ...                            ...   \n",
      "675                 5.412924                       2.000000   \n",
      "676                 5.412924                       2.423090   \n",
      "677                 5.412924                       2.000000   \n",
      "678                 5.412924                       2.000000   \n",
      "679                 5.412924                       2.000000   \n",
      "\n",
      "     Allocated_Officers_Rounded  \n",
      "0                           200  \n",
      "1                           200  \n",
      "2                           182  \n",
      "3                           168  \n",
      "4                           151  \n",
      "..                          ...  \n",
      "675                           2  \n",
      "676                           2  \n",
      "677                           2  \n",
      "678                           2  \n",
      "679                           2  \n",
      "\n",
      "[680 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gurobipy import Model, GRB\n",
    "\n",
    "# Total hours available across all wards\n",
    "allocation_simple_method = pd.read_csv(\"../data/processed/ward_hour_allocation.csv\")\n",
    "total_officers_hours = allocation_simple_method[\"Allocated_Hours\"].sum()\n",
    "\n",
    "file_path = \"../data/processed/sarima_final_forecast_per_ward.csv\"\n",
    "df_full = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "latest_month = df_full[\"Month\"].max()\n",
    "forecast_df = df_full[df_full[\"Month\"] == latest_month].copy()\n",
    "forecast_df = forecast_df.rename(columns={\"mean\": \"Predicted_Crime_Count\"})\n",
    "forecast_df = forecast_df[[\"Ward code\", \"Ward name\", \"Predicted_Crime_Count\"]].reset_index(drop=True)\n",
    "\n",
    "\n",
    "#total_officers = 50000  # total officer‐hours budget\n",
    "\n",
    "demand = forecast_df[\"Predicted_Crime_Count\"].tolist()\n",
    "n = len(demand)\n",
    "\n",
    "m = Model(name=\"ward_allocation_with_bounds\")\n",
    "m.Params.OutputFlag = 1 \n",
    "\n",
    "# Create variables with per‐ward bounds: 2 ≤ x[i] ≤ 200\n",
    "x = []\n",
    "for i in range(n):\n",
    "    xi = m.addVar(vtype=GRB.CONTINUOUS, lb=2.0, ub=200.0, name=f\"x_{i}\")\n",
    "    x.append(xi)\n",
    "\n",
    "# a ≥ 0\n",
    "alpha = m.addVar(vtype=GRB.CONTINUOUS, lb=0.0, name=\"alpha\")\n",
    "\n",
    "#  Add constraints\n",
    "# For each ward i:  x[i] ≥ demand[i] * alpha\n",
    "for i in range(n):\n",
    "    m.addConstr(x[i] >= demand[i] * alpha, name=f\"cover_{i}\")\n",
    "\n",
    "# Sum_i x[i] ≤ total_officers\n",
    "m.addConstr(sum(x) <= total_officers_hours, name=\"total_budget\")\n",
    "\n",
    "# Objective: maximize a\n",
    "m.setObjective(alpha, GRB.MAXIMIZE)\n",
    "\n",
    "m.optimize()\n",
    "\n",
    "if m.status == GRB.Status.OPTIMAL:\n",
    "    alpha_val = alpha.X\n",
    "    allocated_continuous = [xi.X for xi in x]\n",
    "    allocated_rounded = [int(round(val)) for val in allocated_continuous]\n",
    "\n",
    "    forecast_df[\"Alpha (Coverage Factor)\"] = alpha_val\n",
    "    forecast_df[\"Allocated_Officers_Continuous\"] = allocated_continuous\n",
    "    forecast_df[\"Allocated_Officers_Rounded\"] = allocated_rounded\n",
    "\n",
    "    # Sort by rounded allocation\n",
    "    forecast_df = forecast_df.sort_values(\"Allocated_Officers_Rounded\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    print(forecast_df)\n",
    "    forecast_df.to_csv(\"../data/processed/ward_hour_allocation_LP_method\")\n",
    "\n",
    "else:\n",
    "    print(f\"Optimization ended with status {m.status}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f3f98d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/processed/ward_hour_allocation_LP_method.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 1) Load both results\u001b[39;00m\n\u001b[0;32m      5\u001b[0m simple \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/processed/ward_hour_allocation.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m lp     \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/processed/ward_hour_allocation_LP_method.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 2) Load the first‐month SARIMA forecasts\u001b[39;00m\n\u001b[0;32m      9\u001b[0m fc \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     10\u001b[0m     pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/processed/sarima_final_forecast_per_ward.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     11\u001b[0m       \u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMonth == Month.min()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m       [[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWard code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m     13\u001b[0m       \u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForecasted_Burglaries\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m     14\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\20230920\\.conda\\envs\\gurobi-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20230920\\.conda\\envs\\gurobi-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\20230920\\.conda\\envs\\gurobi-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20230920\\.conda\\envs\\gurobi-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\20230920\\.conda\\envs\\gurobi-env\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/processed/ward_hour_allocation_LP_method.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Load both results\n",
    "simple = pd.read_csv(\"../data/processed/ward_hour_allocation.csv\")\n",
    "lp     = pd.read_csv(\"../data/processed/ward_hour_allocation_LP_method.csv\")\n",
    "\n",
    "# 2) Load the first‐month SARIMA forecasts\n",
    "fc = (\n",
    "    pd.read_csv(\"../data/processed/sarima_final_forecast_per_ward.csv\", parse_dates=[\"Month\"])\n",
    "      .query(\"Month == Month.min()\")\n",
    "      [[\"Ward code\", \"mean\"]]\n",
    "      .rename(columns={\"mean\": \"Forecasted_Burglaries\"})\n",
    ")\n",
    "\n",
    "# 3) Merge into one DataFrame\n",
    "df = (\n",
    "    simple\n",
    "    .merge(\n",
    "        lp[[\"Ward code\", \"Allocated_Officers_Rounded\"]]\n",
    "          .rename(columns={\"Allocated_Officers_Rounded\": \"LP_Allocated_Hours\"}),\n",
    "        on=\"Ward code\", how=\"inner\"\n",
    "    )\n",
    "    .merge(fc, on=\"Ward code\", how=\"left\")\n",
    ")\n",
    "\n",
    "# 4) Compute “coverage” = hours allocated ÷ forecast\n",
    "df[\"cov_simple\"] = df[\"Allocated_Hours\"] / df[\"Forecasted_Burglaries\"]\n",
    "df[\"cov_lp\"]     = df[\"LP_Allocated_Hours\"] / df[\"Forecasted_Burglaries\"]\n",
    "\n",
    "# 5) Get summary stats\n",
    "summary = df[[\"cov_simple\",\"cov_lp\"]].agg([\"min\",\"max\",\"mean\",\"std\"]).transpose()\n",
    "print(summary)\n",
    "\n",
    "# 6) (Optional) compute a Gini‐style fairness metric\n",
    "def gini(x):\n",
    "    x = np.sort(x)\n",
    "    n = len(x)\n",
    "    return (2*np.arange(1,n+1).dot(x) / (n*x.sum())) - (n+1)/n\n",
    "\n",
    "print(\"Gini simple method: \", gini(df[\"cov_simple\"]))\n",
    "print(\"Gini LP method:     \", gini(df[\"cov_lp\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be48a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
